{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yelp Review Classification (Positive vs Negative)\n",
    "\n",
    "Data Source: https://www.kaggle.com/c/yelp-recruiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229907, 8)\n",
      "              business_id       date               review_id  stars  \\\n",
      "0  9yKzy9PApeiPPOUJEtnvkg 2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
      "1  ZRJwVLyzEJq1VAihDhYiow 2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
      "2  6oRAC4uyJCsJl1X0WZpVSA 2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
      "3  _1QQZuf4zZOyFCvXc0o6Vg 2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
      "4  6ozycU1RpktNG2-1BroVtw 2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
      "\n",
      "                                                text    type  \\\n",
      "0  My wife took me here on my birthday for breakf...  review   \n",
      "1  I have no idea why some people give bad review...  review   \n",
      "2  love the gyro plate. Rice is so good and I als...  review   \n",
      "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
      "4  General Manager Scott Petello is a good egg!!!...  review   \n",
      "\n",
      "                  user_id                                    votes  \n",
      "0  rLtl8ZkDX5vH5nAx9C3q5Q  {u'funny': 0, u'useful': 5, u'cool': 2}  \n",
      "1  0a2KyEL0d3Yb1V6aivbIuQ  {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "2  0hT2KtfLiobPvh6cDC8JQg  {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "3  uZetl9T0NcROGOyFfughhg  {u'funny': 0, u'useful': 2, u'cool': 1}  \n",
      "4  vYmM4KTsC8ZfQBg-j5MWkw  {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read data to dataframe\n",
    "fname = '../yelp_training_set/yelp_training_set_review.json'\n",
    "data = pd.read_json(fname, lines=True)\n",
    "print(data.shape)\n",
    "print(data.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 2 3 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nresults show:\\nevery line is a review entry;\\nno Null values present\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check information\n",
    "# print('Type contains:')\n",
    "# print(data['type'].unique())\n",
    "# print('Null values:')\n",
    "# print(data.isnull().any())\n",
    "# print(data['stars'].unique())\n",
    "'''\n",
    "results show:\n",
    "every line is a review entry;\n",
    "no Null values present\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  My wife took me here on my birthday for breakf...      1\n",
      "1  I have no idea why some people give bad review...      1\n",
      "2  love the gyro plate. Rice is so good and I als...      1\n",
      "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      1\n",
      "4  General Manager Scott Petello is a good egg!!!...      1\n",
      "\n",
      "                                                    text  label\n",
      "13175  Started coming here the first week it opened, ...      1\n",
      "75390  Thumbs mostly down for me.  Something importan...      0\n",
      "33307  I looooooove ATS! The bean burritos are the be...      1\n",
      "10249  I stopped by for the first time this past week...      1\n",
      "10709  I like to find things to do that just sound fu...      1\n",
      "1    38473\n",
      "0    38473\n",
      "Name: label, dtype: int64\n",
      "\n",
      "X shape: (76946L,)\n",
      "Y shape: (76946L,)\n",
      "\n",
      "1    38473\n",
      "0    38473\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# drop features\n",
    "# since we are only classifying positive and negative reviews, take only the useful features\n",
    "useful_features = ['stars', 'text']\n",
    "data_useful = data.loc[:, useful_features]\n",
    "data_useful = data_useful.loc[data['stars'] != 3]\n",
    "\n",
    "# convert stars to binary values 0 and 1\n",
    "data_useful['label'] = data_useful['stars'].apply(lambda x : 1 if x > 3 else 0)\n",
    "data_useful.drop(['stars'], axis=1, inplace=True)\n",
    "print(data_useful.head())\n",
    "print()\n",
    "\n",
    "# select a subset with equal number of positive and negative reviews\n",
    "data_pos = data_useful.loc[data_useful['label'] == 1]\n",
    "data_neg = data_useful.loc[data_useful['label'] == 0]\n",
    "num_perclass = data_neg.shape[0]\n",
    "data_pos_spl = data_pos.sample(n=num_perclass, random_state=100)\n",
    "data_spl = pd.concat([data_pos_spl, data_neg], ignore_index=True)\n",
    "data_spl = data_spl.reindex(np.random.permutation(data_spl.index))\n",
    "print(data_spl.head())\n",
    "print(data_spl['label'].value_counts())\n",
    "print()\n",
    "\n",
    "# separte x and y data\n",
    "X_data = data_spl['text']\n",
    "Y_data = data_spl['label']\n",
    "print('X shape:', X_data.shape)\n",
    "print('Y shape:', Y_data.shape)\n",
    "print()\n",
    "\n",
    "# check number of positive and negative reviews\n",
    "print(Y_data.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (57709L,)\n",
      "28810\n",
      "Test shape: (19237L,)\n"
     ]
    }
   ],
   "source": [
    "# partition train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, random_state=0)\n",
    "print('Train shape:', X_train.shape)\n",
    "print(sum(y_train == 1))\n",
    "print('Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words Method\n",
    "\n",
    "Use frequency vector of word occurences. It does not keep the order information.\n",
    "Tokenizing and stop-words filtering are done internally.\n",
    "\n",
    "CountVectorizer simply computes the frequency of words. TfidfVectorizaer considers the relative frequency - it pays more attention to the words that have high frequency in certain documents and not all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the tokenization in sklearn simply extract words (ignoring letter case)'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTING\n",
    "# text = pd.Series(['is are Main main, clothes, cloth, mice, mouse running, run, meets, met, meet'])\n",
    "# print(text)\n",
    "# vect = CountVectorizer()\n",
    "# vect.fit(text)\n",
    "# feat_names = vect.get_feature_names()\n",
    "# print(feat_names)\n",
    "'''the tokenization in sklearn simply extract words (ignoring letter case)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features: 1454125\n",
      "(57709, 1454125)\n",
      "(19237, 1454125)\n"
     ]
    }
   ],
   "source": [
    "vect.fit(X_train)\n",
    "feat_names = vect.get_feature_names()\n",
    "print('num_features:', len(feat_names))\n",
    "# print(feat_names[::1000])\n",
    "\n",
    "X_train_vect = vect.transform(X_train)\n",
    "print(X_train_vect.shape)\n",
    "\n",
    "X_test_vect = vect.transform(X_test)\n",
    "print(X_test_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use logistic regression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_vect, y_train)\n",
    "preds = clf.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.929926703748\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "[u'not' u'no' u'bland' u'worst' u'ok' u'bad' u'terrible' u'nothing'\n",
      " u'mediocre' u'rude']\n",
      "\n",
      "Largest Coefs: \n",
      "[u'great' u'love' u'delicious' u'awesome' u'amazing' u'excellent' u'best'\n",
      " u'good' u'perfect' u'definitely']\n"
     ]
    }
   ],
   "source": [
    "feat_names = np.array(feat_names)\n",
    "sorted_coef_index = clf.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feat_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feat_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/\n",
    "- http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "- http://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
